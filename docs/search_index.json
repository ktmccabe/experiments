[["causaleffects.html", "Section 2 Causal Effects", " Section 2 Causal Effects In this section, we discuss causal effects. It builds on Gerber and Green FEDAI Chapter 2. Goal of Causality Isolate the manipulation of one factor (“No causation without manipulation.”), while controlling or “holding everything else constant.” Does border security increase trust in government? Factual: Trust in an environment with border security Counterfactual: Trust in an environment without border security Does gender affect budgetary priorities? Factual: The budget under a village head who is male Counterfactual: The budget under a village head who is female Does race affect one’s job prospect? Factual: Jamal applied for a job but did not get it Counterfactual: Would Jamal have gotten a job if he were white? "],["potential-outcomes-framework.html", "2.1 Potential Outcomes Framework", " 2.1 Potential Outcomes Framework To make causal claims, we compare two states of the world and their potential outcomes: \\(Y_i(d)\\) What is \\(Y_i(0)\\)? What is \\(Y_i(1)\\)? \\(i\\) refers to individual subjects from \\(i = 1\\) to N. \\(d\\) is the treatment indicator \\(d_i\\) refers to whether the subject is treated: \\(d_i = 1\\) or \\(d_i = 0\\) \\(D_i\\) refers to a hypothetical treatment allocation A causal “treatment effect” is then the difference in these potential outcomes: \\(\\tau_i\\) = \\(Y_i(1)\\) - \\(Y_i(0)\\) FEDAI Table 2.1 The treatment effect is the difference between two states of the world: one which a unit receives treatment, and another in which it does not. 2.1.1 Average Treatment Effect The average treatment effect then is the mean of these individual treatment effects: Estimand: On average, how much outcomes would change if all units go from untreated to treated. \\[\\begin{align*} ATE &amp;= \\frac{1}{N} \\sum_{i=1}^N \\tau_i \\\\ &amp;= \\mu_{Y(1)} -\\mu_{Y(0)} \\\\ &amp;= \\frac{1}{N} \\sum_{i=1}^N Y_i (1) - \\frac{1}{N} \\sum_{i=1}^N Y_i (0) \\\\ &amp;= \\frac{1}{N} \\sum_{i=1}^N (Y_i (1)-Y_i (0))\\\\ &amp;= E[Y_i(1) - Y_i(0)]\\\\ \\end{align*}\\] ATE \\(= \\frac{1}{N} \\sum_{i=1}^N \\tau_i\\) is what we want to describe a causal effect, but in real life, we have problems. What are they? Try on your own, then expand for the answer. We only observe one potential outcome. \\(Y_i = d_iY_i(1) + (1-d_i)Y_i(0)\\) (Unless we are in Groundhog Day) "],["fundamental-problem-of-causal-inference.html", "2.2 Fundamental Problem of Causal Inference", " 2.2 Fundamental Problem of Causal Inference We only observe one potential outcome: \\(Y_i\\). \\(Y_i = d_iY_i(1) + (1-d_i)Y_i(0)\\) (Unless we are in Groundhog Day) Example from 2022 Dallas Cowboys game. We only get to observe \\(Y_i\\)= Cowboys lose. After the game, many people said things like: If the Cowboys had handed the ref the ball, \\(Y_i(1)\\) = Cowboys win If the Cowboys had continued to throw the ball instead of run, \\(Y_i(1)\\) = Cowboys win If Dak had just run a shorter distance instead, \\(Y_i(1)\\) = Cowboys win did this seriously just happen pic.twitter.com/MmUk8E1XSL — SB Nation (@SBNation) January 17, 2022 But the fundamental problem of causal inference is that we can only observe one potential outcome, the outcome in this case, under the state of the world \\(Y_i(0)\\) where the play unfolded as it did in the video. It is impossible to observe the actual causal effect of any of the above: \\(Y_i(1) -Y_i(0)\\) "],["identification-strategy.html", "2.3 Identification strategy", " 2.3 Identification strategy We cannot observe the ideal actual causal effect. Instead, we will frame our exercise on the premise that we are randomly sampling our \\(i&#39;s\\) from a population. We then will create an identification strategy. “Ideas that enable researchers to use observable quantities (e.g., sample averages) to reveal parameters of interest (e.g., average treatment effects)” (Gerber and Green 2012, 34) Instead of observing the actual individual causal treatment effect and actual ATE, we develop an estimator for this quantity using the sample averages. A few definitions: The sample average is a random variable, a quantity that varies from sample to sample.1 Expected value is the average outcome of a random variable weighted by its probability of occurrence. Good news: Under random sampling, the expected value of a sample average is the population average. Similarly, the expectation of a randomly selected observation from the population is the population mean. Even though we have a sample, under random sampling, our sample will be unbiased. On average, it’s true. When the expected value of a sample estimate is equal to the population parameter \\(E[\\hat{\\theta}] = \\theta\\), this means our estimator is “unbiased.” Expectation \\[\\begin{align*} E[X]=\\sum x Pr[X=x] \\end{align*}\\] where \\(Pr[X=x]\\) denotes the probability that \\(X\\) takes on the value \\(x\\), and where the summation is taken over all possible values of \\(x\\). Think of this like a weighted average. Example: \\(E[Y_i(1)]\\) is the expected value of the treated potential outcome of a subject who is randomly sampled.(It will equal the average value of all possible values.) What is the value of \\(E[Y_i(1)]\\) in this example? FEDAI Table 2.1 Note: other books may approach this slightly differently by defining a Sample ATE, taking \\(D_i\\) (treatment status) to be the random variable, and \\(Y_i(1)\\) as fixed within a sample. ↩︎ "],["difference-in-means-estimator.html", "2.4 Difference in Means Estimator", " 2.4 Difference in Means Estimator In the real world, we follow this process for causal identification: Our motivation: Find quantities that represent the population parameters (\\(\\theta\\)) Our problem: We often only get a sample of the population and can only observe one potential outcome for any unit in our sample Goal: Get unbiased estimators for the population Definition of unbiasedness: \\(E[\\hat{\\theta}] = \\theta\\) Suppose \\(D_i\\) were randomly assigned such that \\(m\\) subjects assigned to treatment and \\(N-m\\) subjects assigned to control. \\[\\begin{align*} \\widehat{ATE} &amp;= \\frac{1}{m}\\sum_1^m Y_i - \\frac{1}{N-m}\\sum_{m+1}^{N} Y_i \\\\ \\end{align*}\\] Is the difference in means estimator an unbiased estimate for the ATE? How can we find out? We take the expected value: \\[\\begin{align*} E[\\widehat{ATE}] &amp;= E[\\frac{1}{m}\\sum_1^m Y_i - \\frac{1}{N-m}\\sum_{m+1}^{N} Y_i ]\\\\ &amp;= \\frac{1}{m}\\sum_1^m E(Y_i) - \\frac{1}{N-m}\\sum_{m+1}^{N} E(Y_i ) \\\\ &amp;= \\frac{E(Y_1) + E(Y_2) +...+E(Y_m)}{m} - \\frac{E(Y_{m+1}) + E(Y_{m+2}) +...+E(Y_N)}{N-m}\\\\ &amp;= \\frac{m * E[Y_i(1 | D_i = 1)]}{m} - \\frac{(N-m)* E[Y_i(0) | D_i = 0]}{N-m}\\\\ &amp;= E[Y_i(1) | D_i = 1] - E[Y_i(0) | D_i = 0] \\\\ %&amp;= E[Y_i (1)]-E[Y_i (0)]=E[\\tau_i ]=ATE \\end{align*}\\] Is the final statement equivalent to the ATE? We want our final statement to be \\(E[Y_i (1)]-E[Y_i (0)]=E[\\tau_i ]\\)=ATE Our final statement is: \\(E[Y_i(1) | D_i = 1] - E[Y_i(0) | D_i = 0]=E[\\widehat{ATE}]\\) Under what conditions can we get those two statements to look the same? Well, let’s look into some rules of expectation. \\(E[Y|X] = E[Y]\\) if Y and X are independent.2 Our final statement can be simplified when treatment assignment is independent of potential outcomes: \\(E[Y_i(1) |D_i = 1] = E[Y_i(1) |D_i = 0] = E[Y_i(1)]\\) \\(E[Y_i(0) |D_i = 0] = E[Y_i(0) |D_i = 1] = E[Y_i(0)]\\) When does this occur? Random assignment of treatment!! Putting this together, under random assignment: \\[\\begin{align*} E[\\widehat{ATE}] &amp;= E[\\frac{1}{m}\\sum_1^m Y_i - \\frac{1}{N-m}\\sum_{m+1}^{N} Y_i ]\\\\ &amp;= \\frac{1}{m}\\sum_1^m E(Y_i) - \\frac{1}{N-m}\\sum_{m+1}^{N} E(Y_i ) \\\\ &amp;= E[Y_i(1) | D_i = 1] - E[Y_i(0) | D_i = 0] \\\\ &amp;= E[Y_i (1)]-E[Y_i (0)]=E[\\tau_i ]\\\\ E[\\widehat{ATE}] &amp;= ATE \\end{align*}\\] Why Experiments One approach for addressing the fundamental problem of causal inference is to simulate two potential states of the world through random assignment: Randomized Controlled Trials / Experiments Experiments approximate factual vs. counterfactual comparison We randomly assign one group to receive a “treatment” and another not to receive a treatment (the control) Using what we learned above, when treatment assignment is randomized, the only thing that distinguishes the treatment group from the control group in expectation, besides the treatment itself, is chance. This allows us to use a simple differences in means estimator in experiments to estimate our average treatment effects. See video for help on law of iterated expectations↩︎ "],["overview-of-identification-assumptions.html", "2.5 Overview of identification assumptions", " 2.5 Overview of identification assumptions What if we can’t guarantee random assignment? Example: Selection into treatment What if we didn’t have the independence? Subtract and add \\(E[Y_i (0) | D_i=1]\\) to help us illustrate a type of bias that may occur. \\(E[Y_i (1) | D_i=1]-E[Y_i (0) | D_i=0] =\\) \\(\\underbrace{E[Y_i (1) | D_i = 1] - E[Y_i (0) | D_i=1]}_{\\text{Average treatment effect for the treated}} + \\underbrace{E[Y_i (0)|D_i=1]-E[Y_i (0)| D_i=0] }_{\\text{Selection bias}}\\) In observational studies, where assignment into treatment is not random, the second term “Selection bias” may not be zero. E.g., suppose we want to know the effect of minimum wage laws on unemployment. Laws aren’t randomly assigned Possible that states where unemployment (outcome) is lower are less likely to see minimum wage laws passed relative to states where unemployment is higher. If so, the potential outcomes \\(Y_i(0)\\) of states that would hypothetically be treated or untreated would not be the same. Assumptions To “identify” the average treatment effect, we need Probability of treatment of all units is between 0 and 1 Ignorability: \\(Y_i(1), Y_i(0) \\perp D_i\\) (random assignment) Non-interference: \\(Y_i(d_1, d_2, ..., d_n) = Y_i(d)\\), \\(d_i = d\\) Excludability: if \\(Y_i(z, d)\\) where z \\(\\in [0, 1]\\) and \\(d \\in [0, 1]\\), \\(Y_i(1, d) = Y_i(0, d)\\) Let’s put these into plain words. "],["application-in-r.html", "2.6 Application in R", " 2.6 Application in R Article: “Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination” by Bertrand and Mullainathan (2004) Research Question: Does race influence hiring decisions? What are the potential outcomes? What is the approach? Audit study: “send fictitious resumes to help-wanted ads in Boston and Chicago newspapers. Treatment: Manipulate perceived race: resumes randomly assigned African-American- or White-sounding names. Outcomes: Does the resume get a callback? How should we estimate the average treatment effect? 2.6.1 Loading the data We will use data from Imai (2017) Chapter 2. Let’s load the data. Note: When we have variables that are text-based categories, we may want to tell R to treat these “strings” of text information as factor variables, a particular type of variable that represents data as a set of nominal (unordered) or ordinal (ordered) categories. We do this with the stringsAsFactors argument. resume &lt;- read.csv(&quot;resume.csv&quot;, stringsAsFactors = T) resume &lt;- read.csv(&quot;https://raw.githubusercontent.com/ktmccabe/teachingdata/main/resume.csv&quot;, stringsAsFactors = T) Variables and Description firstname: first name of the fictitious job applicant sex: sex of applicant (female or male) race: race of applicant (black or white) call: whether a callback was made (1 = yes, 0 = no) The data contain 4870 resumes and 4 variables. nrow(resume) # number of rows ## [1] 4870 ncol(resume) # number of columns ## [1] 4 dim(resume) # number of rows and columns ## [1] 4870 4 head(resume) ## firstname sex race call ## 1 Allison female white 0 ## 2 Kristen female white 0 ## 3 Lakisha female black 0 ## 4 Latonya female black 0 ## 5 Carrie female white 0 ## 6 Jay male white 0 2.6.2 Variable classes We can check the class of each variable: Look, we have a new type, a “factor” variable. class(resume$firstname) ## [1] &quot;factor&quot; class(resume$sex) ## [1] &quot;factor&quot; class(resume$race) ## [1] &quot;factor&quot; class(resume$call) ## [1] &quot;integer&quot; Rules of Thumb Usually, we want character variables to store text (e.g., open-ended survey responses) We want numeric variables to store numbers. Usually, we want factor variables to store categories. Within R, factor variables assign a number to each category, which is given a label or level in the form of text. Categories might be ordinal or “ordered” (e.g., Very likely, Somewhat likely, Not likely) or Unordered (e.g., “male”, “female”) R won’t know if a factor variable is ordered or unordered. Alas, we have to be smarter than R. R might think you have a character variable when you want it to be a factor or the reverse. That’s when as.factor() and as.character() are useful. Always check class() to find out the variable type 2.6.3 Exploring Treatment and Control Groups We are going to use several different approaches to calculate our difference in means between treatment and control to help us explore R’s capabilities and common computational approaches. We can use the table command to see how many observations in our data fall into each category or numerical value. ## Example: how many black vs. white sounding resumes table(resume$race) ## ## black white ## 2435 2435 As mentioned, factor variables have levels: levels(resume$race) ## [1] &quot;black&quot; &quot;white&quot; We can also use the table command to show a crosstabulation: a table that displays the frequency of observations across two variables. Because our outcome variable call is dichotomous and we are interested in the rates of callbacks, we might use a table to display this information. (For outcomes that are continuous, the table approach is less useful.) ## Example: how many black vs. white sounding resumes by call backs ## We can label the two dimensions of the table with the = table(calledback = resume$call, race = resume$race) ## race ## calledback black white ## 0 2278 2200 ## 1 157 235 Sometimes we will want to show the proportion instead of the frequency using prop.table ## Example: proportion black vs. white sounding resumes by call backs ## Convert to proportion prop.table(table(calledback = resume$call, race = resume$race), margin = 2) # 1 for row sum, 2 for col ## race ## calledback black white ## 0 0.93552361 0.90349076 ## 1 0.06447639 0.09650924 How can we interpret this crosstabulation? 2.6.4 Means with Relational Operators Goal: Compare callback rates for white sounding names to black sounding names, so we need to be able to filter by race. Good news: We have several relational operators in R that evaluate logical statements: ==, &lt;, &gt;, &lt;=, &gt;=, != We have a statement and R evaluates it as TRUE or FALSE ## for each observation, does the value of race equal &quot;black&quot;? resume$race == &quot;black&quot; By putting this logical statement within [ ], we are asking R to take the mean() of the variable resume$call for the subset of observations for which this logical statement is TRUE. mean(resume$call[resume$race == &quot;black&quot;]) ## [1] 0.06447639 Ultimately, each of these paths has led us to a place where we can estimate the average treatment effect by calculation the difference in means: the difference in callback rates for black and white applicants. We said the ATE = \\(\\bar{Y}(treatment) - \\bar{Y}(control)\\) ate &lt;- mean(resume$call[resume$race == &quot;black&quot;]) - mean(resume$call[resume$race == &quot;white&quot;]) ate ## [1] -0.03203285 How can we interpret this? Do white applicants have an advantage? 2.6.5 Means with tidyverse The tidyverse offers a suite of R functions and a different grammar or syntax of coding. Some people prefer this to the “base R” codes we did above. To use this suite, first install the tidyverse package: When you install a package, this is like downloading an app to your phone. You only have to do it one time. install.packages(&quot;tidyverse&quot;) After you have a package installed, much like an app on your phone, you then need to open it before using it in R. To do so, use the library() command. library(tidyverse) The tidyverse works through these piping %&gt;% operators. We can read it from left to right. Take our dataset resume, group the data by race, and within each racial group, summarize the data by taking the mean call back rate. resume %&gt;% group_by(race) %&gt;% summarise(means = mean(call)) ## # A tibble: 2 x 2 ## race means ## &lt;fct&gt; &lt;dbl&gt; ## 1 black 0.0645 ## 2 white 0.0965 We could go a step further to calculate the ATE. ate &lt;- resume %&gt;% group_by(race) %&gt;% summarise(means = mean(call)) %&gt;% ungroup() %&gt;% spread(race, means)%&gt;% mutate(diff = black - white) ate ## # A tibble: 1 x 3 ## black white diff ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0645 0.0965 -0.0320 2.6.6 ATE with linear regression Linear regression also offers a way to calculate the conditional means and difference in means between two groups. In R, we use lm() for this. The syntax is lm(y ~ x, data = mydataframe). fit &lt;- lm(call ~ race, data =resume) We can look at the coefficient results only. fit$coefficients ## (Intercept) racewhite ## 0.06447639 0.03203285 In a regression of this form, the intercept represents the mean of the reference category, in this case, the callback rate for Black applicants. The coefficient on racewhite represents the difference in means between the reference category and this group. I.e., going from a Black applicant (the reference category) to a white applicant, on average, increases call backs by 3.2 percentage points. 2.6.7 Subsetting data in R Maybe we are interested in differences in callbacks for females. One approach for looking at the treatment effect for female applicants, only, is to subset our data to include only female names. To do this, we will assign a new data.frame object that keeps only those rows where sex == \"female\" and retains all columns Below are two approaches for this subsetting, one that uses brackets and one that uses the subset function ## option one females &lt;- resume[resume$sex == &quot;female&quot;, ] ## option two using subset()- preferred females &lt;- subset(resume, sex == &quot;female&quot;) Now that we have subset the data, this simplifies estimating the ATE for female applicants only. We said the ATE = \\(\\bar{Y}(treatment) - \\bar{Y}(control)\\) ate.females &lt;- mean(females$call[females$race == &quot;black&quot;]) - mean(females$call[females$race == &quot;white&quot;]) ate.females ## [1] -0.03264689 Question: Is this an unbiased estimate of the average treatment effect? Try on your own, then expand for the answer. This is an example of a “Conditional Average Treatment Effect.” Generally, because gender is a pre-treatment factor, we can condition on it and get unbiased estimates for the average treatment effect within a particular gender group. Random assignment of treatment means that in expectation, we should have about equal proportions of female applicants in each treatment group, ruling out the potential for selection bias. 2.6.8 Additional Practice We will use data from the article below: Thal, A. (2020). The desire for social status and economic conservatism among affluent Americans. American Political Science Review, 114(2), 426-442. In the experiment, affluent Americans are randomly assigned to encounter Facebook posts in which others broadcast their economic success. These posts are designed in a way that encourages affluent respondents to view economic success as a means of achieving social status. The experiment includes a sample of 2010 affluent Americans– people who report household incomes in the top 10 percent of the U.S. income distribution. Causal Question: Does desire for social status influence economic views of affluent Americans? Randomization: Randomly assign respondents to view different fictional Facebook posts designed to signal different motivations Outcome: An economic conservatism index based on respondents’ support for decreasing “taxes on households making $150,000 or more a year,” support for decreasing the “taxes on money people make from selling investments, also referred to as capital gains,” and support for decreasing “government regulation of business and industry.” Comparison: Average economic views between experimental conditions that vary in the type of social cues given. Let’s load the data! Here, note that the data file is in a .RData format instead of .csv. This means that instead of using read.csv, we should use a function to load the data that is suitable for the .RData format. This will be load. That function works the following way: load(&quot;status.RData&quot;) After running the above code, an object will show up in your R environment. head(status) ## condition male econcon ## 2 Concrete 1 0.7500000 ## 3 Self-Esteem 1 1.0000000 ## 4 Placebo 1 0.6666667 ## 5 Self-Esteem 0 0.2500000 ## 6 Self-Esteem 0 1.0000000 ## 7 Social Approval 0 0.8333333 The data include the following variables condition: Placebo, Concrete, Self-Esteem, Social Approval, Conspicuous Consumption gender: 1= male; 0= otherwise econcon: Economic views. Numeric variable from 0 to 1, with higher values reflecting more conservative views Practice: How many people are in each condition? What is the average treatment effect between the Placebo and Social Approval conditions? Try on your own, then expand for the answer. ## Number of observations table(status$condition) ## ## Placebo Concrete Conspicuous Consumption ## 394 391 392 ## Self-Esteem Social Approval ## 390 375 ## tidy groupmeans &lt;- status %&gt;% group_by(condition) %&gt;% summarise(means = mean(econcon)) %&gt;% ungroup %&gt;% spread(condition, means) groupmeans$`Social Approval` - groupmeans$Placebo ## [1] 0.05634969 ## relational operators ate &lt;- mean(status$econcon[status$condition == &quot;Social Approval&quot;]) - mean(status$econcon[status$condition == &quot;Placebo&quot;]) ate ## [1] 0.05634969 ## regression fit &lt;- lm(econcon ~ condition, data = status) fit$coefficients[&quot;conditionSocial Approval&quot;] ## conditionSocial Approval ## 0.05634969 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
